{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e65af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0a81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTCNN image size: 240\n",
      "MTCNN keeping all faces: True\n",
      "InceptionResnet weight set: vggface2\n"
     ]
    }
   ],
   "source": [
    "mtcnn =  MTCNN(image_size=240, keep_all=True, min_face_size=40, )\n",
    "resnet = InceptionResnetV1(pretrained=\"vggface2\")\n",
    "\n",
    "resnet = resnet.eval()\n",
    "\n",
    "print(f\"MTCNN image size: {mtcnn.image_size}\")\n",
    "print(f\"MTCNN keeping all faces: {mtcnn.keep_all}\")\n",
    "print(f\"InceptionResnet weight set: {resnet.pretrained}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab43230a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known names: ['mary_kom', 'ranveer']\n"
     ]
    }
   ],
   "source": [
    "# We'll also need the library of known faces\n",
    "# Load the `embeddings.pt` file with `torch`\n",
    "embedding_data = torch.load(\"embeddings.pt\")\n",
    "\n",
    "print(f\"Known names: {[data[1] for data in embedding_data]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd2350b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project4\\data\\extracted_frames\n"
     ]
    }
   ],
   "source": [
    "# We'll be getting images uploaded to our app. \n",
    "# But we'll need to test things as we go, so let's get a few sample images.\n",
    "project_dir = Path(\"project4\")\n",
    "images_dir = project_dir / \"data\" / \"extracted_frames\"\n",
    "\n",
    "print(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36f03832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "images_dir = Path(\"project4\") / \"data\" / \"extracted_frames\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ee9829e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'project4\\\\data\\\\extracted_frames\\\\frame_10.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Here are two sample images to test as we go.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sample_single = \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mframe_10.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m sample_multiple = Image.open(images_dir / \u001b[33m\"\u001b[39m\u001b[33mframe_1280.jpg\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Production\\cvproject\\FaceRecognition\\cvenv\\Lib\\site-packages\\PIL\\Image.py:3505\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3502\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3505\u001b[39m     fp = \u001b[43mbuiltins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3506\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'project4\\\\data\\\\extracted_frames\\\\frame_10.jpg'"
     ]
    }
   ],
   "source": [
    "# Here are two sample images to test as we go.\n",
    "sample_single = Image.open(images_dir / \"frame_10.jpg\")\n",
    "sample_multiple = Image.open(images_dir / \"frame_1280.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93eb89a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_single' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msample_single\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_single' is not defined"
     ]
    }
   ],
   "source": [
    "sample_single\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba648e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msample_multiple\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "sample_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442f3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  get the cropped images and probabilities, and the bounding boxes\n",
    "def locate_faces(image):\n",
    "    cropped_images, probs = mtcnn(image, return_prob=True)\n",
    "    boxes, _ = mtcnn.detect(image)\n",
    "\n",
    "    if boxes is None or cropped_images is None:\n",
    "        return []\n",
    "    else:\n",
    "        return list(zip(boxes, probs, cropped_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9eede59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# do a test run on the `sample_multiple`\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m multiple_faces = locate_faces(\u001b[43msample_multiple\u001b[49m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHow many faces in the sample with 5 faces: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(multiple_faces)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "# do a test run on the `sample_multiple`\n",
    "multiple_faces = locate_faces(sample_multiple)\n",
    "print(f\"How many faces in the sample with 5 faces: {len(multiple_faces)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceacfa7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiple_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m face = \u001b[43mmultiple_faces\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFirst bounding box: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mface[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFirst probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mface[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'multiple_faces' is not defined"
     ]
    }
   ],
   "source": [
    "face = multiple_faces[0]\n",
    "print(f\"First bounding box: {face[0]}\")\n",
    "print(f\"First probability: {face[1]}\")\n",
    "print(f\"Shape of first cropped image: {face[2].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdc12542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_name_dist(cropped_image, threshold=0.9):\n",
    "    # Use `resnet` on `cropped_image` to get the embedding.\n",
    "    # Don't forget to unsqueeze!\n",
    "    emb = resnet(cropped_image.unsqueeze(0))\n",
    "\n",
    "    # We'll compute the distance to each known embedding\n",
    "    distances = []\n",
    "    for known_emb, name in embedding_data:\n",
    "        # Use torch.dist to compute the distance between\n",
    "        # `emb` and the known embedding `known_emb`\n",
    "        dist = torch.dist(emb, known_emb).item()\n",
    "        distances.append((dist, name))\n",
    "\n",
    "    # Find the name corresponding to the smallest distance\n",
    "    dist, closest = min(distances)\n",
    "\n",
    "    # If the distance is less than the threshold, set name to closest\n",
    "    # otherwise set name to \"Undetected\"\n",
    "    if dist < threshold:\n",
    "        name = closest\n",
    "    else:\n",
    "        name = \"Undetected\"\n",
    "\n",
    "    return name, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05cd42e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who's in the picture with 5 faces, with distances?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'multiple_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# And to see if it worked, let's run it on our faces.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWho\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms in the picture with 5 faces, with distances?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, face \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mmultiple_faces\u001b[49m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetermine_name_dist(face[\u001b[32m2\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'multiple_faces' is not defined"
     ]
    }
   ],
   "source": [
    "# And to see if it worked, let's run it on our faces.\n",
    "print(\"Who's in the picture with 5 faces, with distances?\")\n",
    "for index, face in enumerate(multiple_faces):\n",
    "    print(f\"{index}: {determine_name_dist(face[2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47e2a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_face(name, dist, box, axis):\n",
    "    \"\"\"Adds a box and a label to the axis from matplotlib\n",
    "    - name and dist are combined to make a label\n",
    "    - box is the four corners of the bounding box for the face\n",
    "    - axis is the return from fig.subplots()\n",
    "    Call this in the same cell as the figure is created\"\"\"\n",
    "\n",
    "    # Add the code to generate a Rectangle for the bounding box\n",
    "    # set the color to \"blue\" and fill to False\n",
    "    rect = plt.Rectangle(\n",
    "            (box[0], box[1]),\n",
    "            box[2] - box[0],\n",
    "            box[3] - box[1],\n",
    "            fill=False,\n",
    "            color=\"blue\",\n",
    "            )\n",
    "\n",
    "    axis.add_patch(rect)\n",
    "\n",
    "    # Set color to be red if the name is \"Undetected\"\n",
    "    # otherwise set it to be blue\n",
    "    if name == \"Undetected\":\n",
    "        color = \"red\"\n",
    "    else:\n",
    "        color= \"blue\"\n",
    "    label = f\"{name} {dist:.2f}\"\n",
    "    axis.text(box[0], box[1], label, fontsize=\"large\", color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8888554",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# To demonstrate how it works, we'll plot the first face found in the multiple faces\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This sets the image size\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# and draws the original image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m width, height = \u001b[43msample_multiple\u001b[49m.size\n\u001b[32m      5\u001b[39m dpi = \u001b[32m96\u001b[39m\n\u001b[32m      6\u001b[39m fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "# To demonstrate how it works, we'll plot the first face found in the multiple faces\n",
    "# This sets the image size\n",
    "# and draws the original image\n",
    "width, height = sample_multiple.size\n",
    "dpi = 96\n",
    "fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "axis = fig.subplots()\n",
    "axis.imshow(sample_multiple)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "face = multiple_faces[0]\n",
    "cropped_image = face[2]\n",
    "box = face[0]\n",
    "\n",
    "name, dist = determine_name_dist(cropped_image)\n",
    "\n",
    "label_face(name, dist, box, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3388c63",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m width, height = \u001b[43msample_multiple\u001b[49m.size\n\u001b[32m      2\u001b[39m dpi = \u001b[32m96\u001b[39m\n\u001b[32m      3\u001b[39m fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "width, height = sample_multiple.size\n",
    "dpi = 96\n",
    "fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "axis = fig.subplots()\n",
    "axis.imshow(sample_multiple)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3aa15e79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'multiple_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mmultiple_faces\u001b[49m[\u001b[32m0\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'multiple_faces' is not defined"
     ]
    }
   ],
   "source": [
    "len(multiple_faces[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e64c649d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Fill in the needed loop to go over the faces in `multiple_faces`.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# This sets the image size\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# and draws the original image\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m width, height = \u001b[43msample_multiple\u001b[49m.size\n\u001b[32m      5\u001b[39m dpi = \u001b[32m96\u001b[39m\n\u001b[32m      6\u001b[39m fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "# Fill in the needed loop to go over the faces in `multiple_faces`.\n",
    "# This sets the image size\n",
    "# and draws the original image\n",
    "width, height = sample_multiple.size\n",
    "dpi = 96\n",
    "fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "axis = fig.subplots()\n",
    "axis.imshow(sample_multiple)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "for face in multiple_faces:\n",
    "    box, prob, cropped_image = face\n",
    "\n",
    "    name, dist = determine_name_dist(cropped_image)\n",
    "\n",
    "    label_face(name, dist, box, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4a2d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels_to_image(image):\n",
    "    # This sets the image size\n",
    "    # and draws the original image\n",
    "    width, height = image.width, image.height\n",
    "    dpi = 96\n",
    "    fig = plt.figure(figsize=(width / dpi, height / dpi), dpi=dpi)\n",
    "    axis = fig.subplots()\n",
    "    axis.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Use the function locate_faces to get the individual face info\n",
    "    faces = locate_faces(image)\n",
    "\n",
    "    for box, prob, cropped in faces:\n",
    "        # If the probability is less than 0.90,\n",
    "        # It's not a face, skip this run of the loop with continue\n",
    "        if prob < 0.9:\n",
    "            continue\n",
    "        \n",
    "        # Call determine_name_dist to get the name and distance\n",
    "        name, dist = determine_name_dist(cropped)\n",
    "\n",
    "        # Use label_face to draw the box and label on this face\n",
    "        label_face(name, dist, box, axis)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ca24ba1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# We can test this by running it on our `sample_multiple` (the original image). \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m labeled_multiple = add_labels_to_image(\u001b[43msample_multiple\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "# We can test this by running it on our `sample_multiple` (the original image). \n",
    "labeled_multiple = add_labels_to_image(sample_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58e66fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeled_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlabeled_multiple\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'labeled_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "labeled_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa1e9578",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_single' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Call our `add_labels_to_image` function on `sample_single` \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# and save the result to `labeled_single`.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m labeled_single = add_labels_to_image(\u001b[43msample_single\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'sample_single' is not defined"
     ]
    }
   ],
   "source": [
    "#Call our `add_labels_to_image` function on `sample_single` \n",
    "# and save the result to `labeled_single`.\n",
    "labeled_single = add_labels_to_image(sample_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fdfeadb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labeled_single' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlabeled_single\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'labeled_single' is not defined"
     ]
    }
   ],
   "source": [
    "labeled_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19760d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mface_recognition\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'face_recognition'"
     ]
    }
   ],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e60cfa94",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_recognition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mface_recognition\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'face_recognition' is not defined"
     ]
    }
   ],
   "source": [
    "face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a17af4c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'face_recognition' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m test_multiple = \u001b[43mface_recognition\u001b[49m.add_labels_to_image(sample_multiple)\n",
      "\u001b[31mNameError\u001b[39m: name 'face_recognition' is not defined"
     ]
    }
   ],
   "source": [
    "test_multiple = face_recognition.add_labels_to_image(sample_multiple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88b64892",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_multiple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_multiple\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'test_multiple' is not defined"
     ]
    }
   ],
   "source": [
    "test_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e91088fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'app'"
     ]
    }
   ],
   "source": [
    "import app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38232e73",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'app' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mapp\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33madd_labels_to_image\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mimport not successful\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'app' is not defined"
     ]
    }
   ],
   "source": [
    "assert hasattr(app, \"add_labels_to_image\"), \"import not successful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ecb60f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'project4/data/images/mary_kom/frame_115.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Tests if the image processing worked\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# you'll get an error if it didn't\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproject4/data/images/mary_kom/frame_115.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m res = app.run_face_recognition(f)\n\u001b[32m      5\u001b[39m f.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Production\\cvproject\\cvenv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:327\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    322\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    325\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'project4/data/images/mary_kom/frame_115.jpg'"
     ]
    }
   ],
   "source": [
    "# Tests if the image processing worked\n",
    "# you'll get an error if it didn't\n",
    "f = open(\"project4/data/images/mary_kom/frame_115.jpg\", \"rb\")\n",
    "res = app.run_face_recognition(f)\n",
    "f.close()\n",
    "\n",
    "assert isinstance(res, matplotlib.figure.Figure), \"Image did not process\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
